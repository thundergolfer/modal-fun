import dataclasses
import pathlib


@dataclasses.dataclass
class ModelSpec:
    name: str
    params: str
    relative_speed: int  # Higher is faster


CACHE_DIR = "/cache"
# Where downloaded podcasts are stored, by guid hash.
# Mostly .mp3 files 50-100MiB.
RAW_AUDIO_DIR = pathlib.Path(CACHE_DIR, "raw_audio")
# Stores metadata of individual podcast episodes as JSON.
# nb: Should probably be called EPISODES_METADATA_DIR.
METADATA_DIR = pathlib.Path(CACHE_DIR, "metadata")
PODCAST_METADATA_DIR = pathlib.Path(CACHE_DIR, "podcast_metadata")
# Crude boolean marker of a previously processed podcast.
COMPLETED_DIR = pathlib.Path(CACHE_DIR, "completed")
# Completed episode transcriptions. Stored as flat files with
# files structured as '{guid_hash}-{model_slug}.json'.
TRANSCRIPTIONS_DIR = pathlib.Path(CACHE_DIR, "transcriptions")
# Searching indexing files, refreshed by scheduled functions.
SEARCH_DIR = pathlib.Path(CACHE_DIR, "search")
# Location of web frontend assets.
ASSETS_PATH = pathlib.Path(__file__).parent / "web"
# TODO: Remove
podchaser_podcast_ids = {
    "ezra_klein_nyt": 1582975,
    "ezra_klein_vox": 82327,
    "lex_fridman": 721928,
    "The Joe Rogan Experience": 10829,
}

# Remove when CPU processing works, or when GPUs plummet in cost.
transcripts_per_podcast_limit = 5

supported_whisper_models = {
    "tiny.en": ModelSpec(name="tiny.en", params="39M", relative_speed=32),
    # Takes around 3-10 minutes to transcribe a podcast, depending on length.
    "base.en": ModelSpec(name="base.en", params="74M", relative_speed=16),
    "small.en": ModelSpec(name="small.en", params="244M", relative_speed=6),
    "medium.en": ModelSpec(name="medium.en", params="769M", relative_speed=2),
    # Very slow. Will take around 45 mins to 1.5 hours to transcribe.
    "large": ModelSpec(name="large", params="1550M", relative_speed=1),
}
